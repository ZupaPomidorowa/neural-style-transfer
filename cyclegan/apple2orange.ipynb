{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dated-copying",
   "metadata": {},
   "source": [
    "# Zamiana jabłek na pomarańcze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-doubt",
   "metadata": {},
   "source": [
    "CycleGAN - umożliwia przekształcenia obrazów w obu kierunkach, 4 modele, 2 dyskryminatory i 2 generatory; \n",
    "\n",
    "Generatory:\n",
    "* G_AB - obrazy z domeny A do domeny B\n",
    "* G_BA - obrazy z domeny B do domeny A\n",
    "\n",
    "Dyskryminatory:\n",
    "* d_A - różnica między autentycznymi obrazami A a wytworzonymi przez G_AB\n",
    "* d_B - różnica między autentycznymi obrazami B a wytworzonymi przez G_BA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preceding-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.cycleGAN import CycleGAN\n",
    "from utils.loaders import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-spelling",
   "metadata": {},
   "source": [
    "W models.cycleGAN tworzymy obiekt CycleGAN który możemy nastepnie modyfikować\n",
    "Generatory: U-Net (models.cycleGAN) , ResNet\n",
    "\n",
    "U-Net\n",
    "* downsampling - kompresowanie przestrzenne, ale rozbudowane pod względem kanałów\n",
    "* upsampling - rozwijane przestrzennie, redukcja kanałów \n",
    "* Na wierzchołku u kontekstowe rozumienie czym jest obraz\n",
    "* Pomijanie połączeń przepływ do dalszych warstw, scalenie stylu z zawartością obrazu\n",
    "* Warstwa Concatenate - pomijanie połączeń, łączy downsampling z upsampling, liczba kanałów do 2k\n",
    "* Warswa InstanceNormalization - normalizuje obserwacje indywidualnie (partia, warstwa, próbka, grupa), nie uczy wag, normalizacja obserwacji nie warstw\n",
    "\n",
    "Dwie połówki:\n",
    "-downsampling - Conv2D, krok 2\n",
    "-upsampling - warstwy Concatenate\n",
    "\n",
    "\n",
    "Dyskryminatory\n",
    "\n",
    "Wyjście w postaci 8x8, podział na łaty i odgaduje czy są prawdziwe, prawdopodobieństwo dla każdej łaty, łaty oceniane równocześnie.\n",
    "\n",
    "Zaleta: funkcja straty może mierzyć na podstawie stylu\n",
    "\n",
    "* Zbiór warstw konwolucyjnych\n",
    "* Wszystkie warstwy (oprócz 1) normalizacja \n",
    "* Ostatnia warstwa bez konwolucyjna z 1 filtrem, bez aktywacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "yellow-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'paint'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'apple2orange'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' # 'build' # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-testament",
   "metadata": {},
   "source": [
    "**Dane**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neural-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compressed-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset_name=DATA_NAME, img_res=(IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-frontier",
   "metadata": {},
   "source": [
    "**Budowa sieci**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abstract-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = CycleGAN(\n",
    "    input_dim = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "    ,learning_rate = 0.0002\n",
    "    , buffer_max_length = 50\n",
    "    , lambda_validation = 1\n",
    "    , lambda_reconstr = 10\n",
    "    , lambda_id = 2\n",
    "    , generator_type = 'unet'\n",
    "    , gen_n_filters = 32\n",
    "    , disc_n_filters = 32\n",
    "    )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-bookmark",
   "metadata": {},
   "source": [
    "g_AB - konwertowanie obrazu A na B\n",
    "\n",
    "g_BA - konwetowanie obrazu B na A\n",
    "\n",
    "d_A - różnica między autentycznymi obrazami A a fałszywymi generowanymi przez g_BA\n",
    "\n",
    "d_B - różnica między autentycznymi obrazami A a fałszywymi generowanymi przez g_BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dynamic-philosophy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 32)   1568        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_6 (Insta (None, 64, 64, 32)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 32)   0           instance_normalization_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 64)   32832       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_7 (Insta (None, 32, 32, 64)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 64)   0           instance_normalization_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 128)  131200      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_8 (Insta (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 128)  0           instance_normalization_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    524544      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_9 (Insta (None, 8, 8, 256)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 256)    0           instance_normalization_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 16, 16, 256)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  524416      up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, 16, 16, 128)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 128)  0           instance_normalization_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 256)  0           activation_4[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 64)   262208      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, 32, 32, 64)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 64)   0           instance_normalization_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 128)  0           activation_5[0][0]               \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 32)   65568       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, 64, 64, 32)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 32)   0           instance_normalization_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 64)   0           activation_6[0][0]               \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 3)  3075        up_sampling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,545,411\n",
      "Trainable params: 1,545,411\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.g_AB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reduced-sherman",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 32)   1568        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, 64, 64, 32)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 32)   0           instance_normalization_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 64)   32832       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, 32, 32, 64)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 64)   0           instance_normalization_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 128)  131200      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, 16, 16, 128)  0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 128)  0           instance_normalization_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 256)    524544      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, 8, 8, 256)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 256)    0           instance_normalization_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 256)  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 128)  524416      up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, 16, 16, 128)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 128)  0           instance_normalization_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 256)  0           activation_11[0][0]              \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 256)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   262208      up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, 32, 32, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 64)   0           instance_normalization_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 128)  0           activation_12[0][0]              \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 32)   65568       up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, 64, 64, 32)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 32)   0           instance_normalization_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 64)   0           activation_13[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 3)  3075        up_sampling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,545,411\n",
      "Trainable params: 1,545,411\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.g_BA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mediterranean-theory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        1568      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        32832     \n",
      "_________________________________________________________________\n",
      "instance_normalization (Inst (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 256)       524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 1)         4097      \n",
      "=================================================================\n",
      "Total params: 694,241\n",
      "Trainable params: 694,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.d_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minimal-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 32)        1568      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        32832     \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_4 (In (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 256)       524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_5 (In (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 1)         4097      \n",
      "=================================================================\n",
      "Total params: 694,241\n",
      "Trainable params: 694,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.d_B.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-course",
   "metadata": {},
   "source": [
    "Kompilacja dyskryminatory - bezpośrednio, mamy wejścia oraz binarne wyjścia\n",
    "\n",
    "Kompilacja generatory - nie mamy sparowanych obrazów w zestawie danych, kryteria oceny:\n",
    "* poprawność - czy można oszukać dyskryminatory\n",
    "\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "* rekonstrukcja - powrót do orginalnego obrazu\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "* tożsamość - obraz niezmieniony jeśli zastosujemy każdy z generatorów\n",
    "        img_A_id = self.g_BA(img_A)\n",
    "        img_B_id = self.g_AB(img_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stock-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 2\n",
    "PRINT_EVERY_N_BATCHES = 10\n",
    "\n",
    "TEST_A_FILE = 'n07740461_14740.jpg'\n",
    "TEST_B_FILE = 'n07749192_4241.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-humanitarian",
   "metadata": {},
   "source": [
    "* Szkolenie naprzemienne dyskryminatorów i generatorów\n",
    "* Obrazy autentyczne 1, wygenerowane 0\n",
    "        valid = np.ones\n",
    "        fake = np.zeros\n",
    "* Generator - fałszywe obrazy - trenowanie dyskryminatora\n",
    "* Generatory szkolone razem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "constant-repeat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 0/995] [D loss: 1.280687, acc:  58%] [G loss: 16.858515, adv: 2.332528, recon: 1.192468, id: 1.300652] time: 0:00:00.185331 \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'weakref' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-35fa8e71adeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gan.train(data_loader\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m,\u001b[0m \u001b[0mtest_A_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTEST_A_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m,\u001b[0m \u001b[0mtest_B_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTEST_B_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs-home/Daria_Danieluk/projekt_indywidualny_obrazy/apple2orange/models/cycleGAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, run_folder, epochs, test_A_file, test_B_file, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    339\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights/weights-%d.h5'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights/weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs-home/Daria_Danieluk/projekt_indywidualny_obrazy/apple2orange/models/cycleGAN.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, run_folder)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'weakref' object"
     ]
    }
   ],
   "source": [
    "gan.train(data_loader\n",
    "        , run_folder = RUN_FOLDER\n",
    "        , epochs=EPOCHS\n",
    "        , test_A_file = TEST_A_FILE\n",
    "        , test_B_file = TEST_B_FILE\n",
    "        , batch_size=BATCH_SIZE\n",
    "        , sample_interval=PRINT_EVERY_N_BATCHES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-jefferson",
   "metadata": {},
   "source": [
    "**Strata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot([x[1] for x in gan.g_losses], color='green', linewidth=0.1) #DISCRIM LOSS\n",
    "# plt.plot([x[2] for x in gan.g_losses], color='orange', linewidth=0.1)\n",
    "plt.plot([x[3] for x in gan.g_losses], color='blue', linewidth=0.1) #CYCLE LOSS\n",
    "# plt.plot([x[4] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "plt.plot([x[5] for x in gan.g_losses], color='red', linewidth=0.25) #ID LOSS\n",
    "# plt.plot([x[6] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[0] for x in gan.g_losses], color='black', linewidth=0.25)\n",
    "\n",
    "# plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.ylim(0, 5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd_kernel",
   "language": "python",
   "name": "dd_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
