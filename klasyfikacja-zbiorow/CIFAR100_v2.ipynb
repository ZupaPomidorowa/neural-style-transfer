{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quality-niagara",
   "metadata": {},
   "source": [
    "# Klasyfikacja zbioru CIFAR-100\n",
    "Pr√≥by poprawy wyniku z CIFAR100_GDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sexual-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K \n",
    "\n",
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-terry",
   "metadata": {},
   "source": [
    "**Dane**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "internal-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-latin",
   "metadata": {},
   "source": [
    "**Budowa sieci**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input((32,32,3))\n",
    "\n",
    "x = Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = 'same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fluid-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 564,484\n",
      "Trainable params: 563,332\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-october",
   "metadata": {},
   "source": [
    "**Trenowanie sieci**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "descending-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "visible-norway",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "782/782 [==============================] - 8s 9ms/step - loss: 0.7057 - accuracy: 0.7811 - val_loss: 3.5277 - val_accuracy: 0.3840\n",
      "Epoch 2/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.7531 - accuracy: 0.7674 - val_loss: 3.7384 - val_accuracy: 0.3614\n",
      "Epoch 3/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6835 - accuracy: 0.7862 - val_loss: 3.6289 - val_accuracy: 0.3662\n",
      "Epoch 4/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6741 - accuracy: 0.7840 - val_loss: 3.2775 - val_accuracy: 0.3948\n",
      "Epoch 5/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6650 - accuracy: 0.7896 - val_loss: 3.3286 - val_accuracy: 0.3929\n",
      "Epoch 6/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6303 - accuracy: 0.8002 - val_loss: 3.4110 - val_accuracy: 0.3828\n",
      "Epoch 7/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.5903 - accuracy: 0.8149 - val_loss: 3.3932 - val_accuracy: 0.3940\n",
      "Epoch 8/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.5831 - accuracy: 0.8139 - val_loss: 3.3968 - val_accuracy: 0.3916\n",
      "Epoch 9/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.5635 - accuracy: 0.8209 - val_loss: 3.4766 - val_accuracy: 0.3824\n",
      "Epoch 10/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.5493 - accuracy: 0.8252 - val_loss: 3.5615 - val_accuracy: 0.3816\n",
      "Epoch 11/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.5254 - accuracy: 0.8327 - val_loss: 3.5375 - val_accuracy: 0.3875\n",
      "Epoch 12/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.5016 - accuracy: 0.8405 - val_loss: 3.6501 - val_accuracy: 0.3739\n",
      "Epoch 13/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.4928 - accuracy: 0.8425 - val_loss: 3.6257 - val_accuracy: 0.3866\n",
      "Epoch 14/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.4614 - accuracy: 0.8514 - val_loss: 3.6620 - val_accuracy: 0.3875\n",
      "Epoch 15/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.4704 - accuracy: 0.8503 - val_loss: 3.6239 - val_accuracy: 0.3858\n",
      "Epoch 16/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.4521 - accuracy: 0.8552 - val_loss: 3.6023 - val_accuracy: 0.3932\n",
      "Epoch 17/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.4171 - accuracy: 0.8670 - val_loss: 3.7427 - val_accuracy: 0.3948\n",
      "Epoch 18/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3974 - accuracy: 0.8715 - val_loss: 3.7708 - val_accuracy: 0.3928\n",
      "Epoch 19/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.4213 - accuracy: 0.8662 - val_loss: 3.9651 - val_accuracy: 0.3662\n",
      "Epoch 20/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3959 - accuracy: 0.8712 - val_loss: 3.8846 - val_accuracy: 0.3847\n",
      "Epoch 21/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3949 - accuracy: 0.8729 - val_loss: 4.1898 - val_accuracy: 0.3779\n",
      "Epoch 22/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3859 - accuracy: 0.8753 - val_loss: 3.8894 - val_accuracy: 0.3872\n",
      "Epoch 23/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3810 - accuracy: 0.8755 - val_loss: 3.9959 - val_accuracy: 0.3865\n",
      "Epoch 24/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3538 - accuracy: 0.8859 - val_loss: 3.9121 - val_accuracy: 0.3890\n",
      "Epoch 25/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3528 - accuracy: 0.8854 - val_loss: 4.0725 - val_accuracy: 0.3876\n",
      "Epoch 26/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3304 - accuracy: 0.8932 - val_loss: 3.9595 - val_accuracy: 0.3891\n",
      "Epoch 27/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3321 - accuracy: 0.8920 - val_loss: 4.0181 - val_accuracy: 0.3864\n",
      "Epoch 28/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3404 - accuracy: 0.8906 - val_loss: 4.0779 - val_accuracy: 0.3866\n",
      "Epoch 29/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3290 - accuracy: 0.8940 - val_loss: 4.0716 - val_accuracy: 0.3964\n",
      "Epoch 30/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3018 - accuracy: 0.9012 - val_loss: 4.1880 - val_accuracy: 0.3852\n",
      "Epoch 31/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3272 - accuracy: 0.8933 - val_loss: 4.0706 - val_accuracy: 0.3940\n",
      "Epoch 32/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3015 - accuracy: 0.9022 - val_loss: 4.2771 - val_accuracy: 0.3878\n",
      "Epoch 33/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3036 - accuracy: 0.9002 - val_loss: 4.1379 - val_accuracy: 0.3906\n",
      "Epoch 34/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2854 - accuracy: 0.9052 - val_loss: 4.1083 - val_accuracy: 0.3910\n",
      "Epoch 35/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2666 - accuracy: 0.9136 - val_loss: 4.3345 - val_accuracy: 0.3900\n",
      "Epoch 36/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2845 - accuracy: 0.9072 - val_loss: 4.2224 - val_accuracy: 0.3893\n",
      "Epoch 37/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2768 - accuracy: 0.9092 - val_loss: 4.2421 - val_accuracy: 0.3906\n",
      "Epoch 38/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2755 - accuracy: 0.9114 - val_loss: 4.5078 - val_accuracy: 0.3814\n",
      "Epoch 39/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2715 - accuracy: 0.9126 - val_loss: 4.4080 - val_accuracy: 0.3825\n",
      "Epoch 40/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2610 - accuracy: 0.9154 - val_loss: 4.3700 - val_accuracy: 0.3912\n",
      "Epoch 41/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2476 - accuracy: 0.9197 - val_loss: 4.2921 - val_accuracy: 0.3952\n",
      "Epoch 42/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2536 - accuracy: 0.9175 - val_loss: 4.3699 - val_accuracy: 0.3942\n",
      "Epoch 43/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2429 - accuracy: 0.9197 - val_loss: 4.3705 - val_accuracy: 0.3936\n",
      "Epoch 44/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2358 - accuracy: 0.9218 - val_loss: 4.4594 - val_accuracy: 0.3959\n",
      "Epoch 45/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2337 - accuracy: 0.9233 - val_loss: 4.3958 - val_accuracy: 0.3946\n",
      "Epoch 46/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2396 - accuracy: 0.9219 - val_loss: 4.5736 - val_accuracy: 0.3880\n",
      "Epoch 47/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2292 - accuracy: 0.9242 - val_loss: 4.5375 - val_accuracy: 0.3904\n",
      "Epoch 48/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2294 - accuracy: 0.9243 - val_loss: 4.5076 - val_accuracy: 0.3895\n",
      "Epoch 49/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2225 - accuracy: 0.9265 - val_loss: 4.5314 - val_accuracy: 0.3877\n",
      "Epoch 50/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2181 - accuracy: 0.9292 - val_loss: 4.8307 - val_accuracy: 0.3786\n",
      "Epoch 51/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2173 - accuracy: 0.9278 - val_loss: 4.5332 - val_accuracy: 0.3800\n",
      "Epoch 52/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2222 - accuracy: 0.9281 - val_loss: 4.6089 - val_accuracy: 0.3852\n",
      "Epoch 53/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2168 - accuracy: 0.9288 - val_loss: 4.5270 - val_accuracy: 0.3892\n",
      "Epoch 54/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2123 - accuracy: 0.9305 - val_loss: 4.4988 - val_accuracy: 0.3858\n",
      "Epoch 55/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1971 - accuracy: 0.9351 - val_loss: 4.6609 - val_accuracy: 0.3915\n",
      "Epoch 56/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2082 - accuracy: 0.9325 - val_loss: 4.5878 - val_accuracy: 0.3948\n",
      "Epoch 57/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2129 - accuracy: 0.9315 - val_loss: 4.7054 - val_accuracy: 0.3902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2040 - accuracy: 0.9349 - val_loss: 4.7828 - val_accuracy: 0.3821\n",
      "Epoch 59/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1941 - accuracy: 0.9365 - val_loss: 4.6173 - val_accuracy: 0.3913\n",
      "Epoch 60/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1876 - accuracy: 0.9381 - val_loss: 4.7166 - val_accuracy: 0.3840\n",
      "Epoch 61/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1956 - accuracy: 0.9353 - val_loss: 4.7559 - val_accuracy: 0.3864\n",
      "Epoch 62/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1927 - accuracy: 0.9384 - val_loss: 4.8158 - val_accuracy: 0.3895\n",
      "Epoch 63/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1868 - accuracy: 0.9367 - val_loss: 4.7582 - val_accuracy: 0.3899\n",
      "Epoch 64/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1839 - accuracy: 0.9395 - val_loss: 4.8597 - val_accuracy: 0.3863\n",
      "Epoch 65/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1951 - accuracy: 0.9361 - val_loss: 4.8784 - val_accuracy: 0.3860\n",
      "Epoch 66/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1769 - accuracy: 0.9420 - val_loss: 4.8384 - val_accuracy: 0.3861\n",
      "Epoch 67/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1771 - accuracy: 0.9414 - val_loss: 4.8408 - val_accuracy: 0.3900\n",
      "Epoch 68/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1765 - accuracy: 0.9415 - val_loss: 4.8461 - val_accuracy: 0.3897\n",
      "Epoch 69/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1869 - accuracy: 0.9392 - val_loss: 4.8644 - val_accuracy: 0.3929\n",
      "Epoch 70/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1745 - accuracy: 0.9418 - val_loss: 4.8875 - val_accuracy: 0.3920\n",
      "Epoch 71/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1812 - accuracy: 0.9412 - val_loss: 4.9195 - val_accuracy: 0.3865\n",
      "Epoch 72/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1759 - accuracy: 0.9415 - val_loss: 4.8947 - val_accuracy: 0.3914\n",
      "Epoch 73/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1749 - accuracy: 0.9417 - val_loss: 4.8338 - val_accuracy: 0.3850\n",
      "Epoch 74/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1695 - accuracy: 0.9455 - val_loss: 4.9955 - val_accuracy: 0.3876\n",
      "Epoch 75/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1673 - accuracy: 0.9451 - val_loss: 4.9091 - val_accuracy: 0.3844\n",
      "Epoch 76/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1686 - accuracy: 0.9461 - val_loss: 5.0068 - val_accuracy: 0.3859\n",
      "Epoch 77/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1651 - accuracy: 0.9476 - val_loss: 4.9143 - val_accuracy: 0.3867\n",
      "Epoch 78/200\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1738 - accuracy: 0.9428 - val_loss: 4.9579 - val_accuracy: 0.3893\n",
      "Epoch 79/200\n",
      "123/782 [===>..........................] - ETA: 5s - loss: 0.1529 - accuracy: 0.9513"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-f3442462d053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(x_train\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train\n",
    "          , y_train\n",
    "          , batch_size=64\n",
    "          , epochs=200\n",
    "          , shuffle=True\n",
    "          , validation_data = (x_test, y_test))\n",
    "\n",
    "model.save('cifar100_model3.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('cifar100_model3.h5')\n",
    "model.evaluate(x_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES =  np.array(['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', \n",
    "           'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', \n",
    "           'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', \n",
    "           'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', \n",
    "           'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', \n",
    "           'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n",
    "           'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', \n",
    "           'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', \n",
    "           'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']) \n",
    "\n",
    "preds = model.predict(x_test)\n",
    "preds_single = CLASSES[np.argmax(preds, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = x_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.7, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    ax.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd_kernel",
   "language": "python",
   "name": "dd_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
